<HTML>
<HEAD>
<TITLE>Logic: How the Mind Seeks Truth</TITLE>
  <link rel="shortcut icon" href="/Master/qhst.ico" />
  <link rel="stylesheet" type="text/css" href="/Master/QHST.css" />
  <script src="/Master/NavigateButtonSupport.js"></script>
</HEAD>
<body>
  <script src="/Master/QHSTPageBegin.js"></script>
<font face=arial, helvetica,swiss size=2>
<P>
<b>A. How the mind seeks truth</b>
<P>
The following is taken from Thomas Gilovich,<i>How We Know What
Isn't So</i>, New York: The Free Press, 1991.
<P>
I. Cognitive Determinants of Questionable Beliefs
<P>
A. Something Out of Nothing: The misperception and misinterpretation
of random data
<P>
1. infertal couples who adopt will be more likely to conceive
than similar couples who do not.
<P>
Several things need to made clear right at the beginning: &quot;First,
people do not hold questionable beliefs simply because they have
not been exposed to the relevant evidence. Erroneous beliefs plague
both experienced professionals and less informed laypeople alike.&quot;
<P>
&quot;Nor do people hold questionable beliefs because they are
stupid or gullible.&quot;
<P>
Rather, many questionable and erroneous beliefs have purely cognitive
origins, and can be traced to imperfections in our capacities
to process information and draw conclusions...we hold many dubious
beliefs, in other words, not because they satisfy some important
psychological need, but because they seem to be the most sensible
conclusions consistent with the available evidence.
<P>
&quot;People hold such beliefs because tey seem in the words of
Robert Merton, too be the 'irresistable products of their own
experience.' They are the products, not of irrationality, but
of flawed rationality.
<P>
-- newsworthiness of those who adopt and then have children
<P>
a. misperception of random events
<P>
canals on mars
<P>
&quot;the hot hand&quot; vs. &quot;gone cold&quot;: success breeds
success; failure breeds failure
<P>
a. tendency for people's preconceptions to bias their interpretations
of what they see.
<P>
Streaks of successive hits or misses may stand out and be remembered,
while sequences of frequent alternation between the two may go
unnoticed and be forgotten. Or the common occurrence of a shot
popping out of the basket after having seemingly been made might
be counted as a &quot;near miss&quot; if the player had made his
last several shots, but as evidence of being extreamly cold if
the player had missed his last several shots. (the biasing effects
of peoples theories and preconceptions II.A)
<P>
b. People have faulty intuitions about what chance sequences look
like. People expect sequences of coin flips, for example, to alternate
between heads and tails more than they actually do. Because chance
produces less alternation than our intuition leads us to expect,
truly random sequences look too ordered or 'lumpy'. Streaks of
4, 5, or 6 heads in a row clash with our expectations about the
behavior of a fair coin, although in a series of 20 tosses there
is a 50-50 chances of getting 4 heads in a row, a 25 percent chance
of five in a row, and a 10 percent chance of a streak of six.
Because the average basketball player makes about 50 % of his
shots, he has a reasonably good chance of looking like he has
the hot hand by making four, five, or even six shots in a row
if he takes 20 shots in a game (as many players do).
<P>
-- The Clustering Illusion
<P>
-- Judgment by Representativeness
<P>
People have a reflexive tendency to assess the similarity of outcomes,
instances, and categories on relatively salient and even superficial
features, and then to use these assessments of similarity as a
basis of judgment. &quot;Like goes with like&quot; people assume.
Things that go together should look like they go together.
<P>
Thus, develop prejudices --librarians look like librarians.
<P>
Spicy food is the cause of heartburn, not the bland food we had.
<P>
Sometimes this is not a bad principle, but the overapplication
of it is when it gets us into trouble.
<P>
---Misperceptions of Random Dispersions
<P>
births of boys and girls
<P>
the stock market
<P>
--Causal Theories
<P>
The major point of all this: we have difficulty accurately recognizing
random arrangements of events.
<P>
B. Too Much from Too Little: The misinterpretation of Incomplete
and Unrepresentative Data
<P>
I've seen it happen. You see it all the time. I know someone who
did.
<P>
C. Seeing What We Expect to See: The biased evaluation of ambiguious
and inconsistent Data
<P>
You have to believe in order to see. He was out, he was out by
a mile. Of course he was up to no good. We're talking about, xxx,
aren't we?
<P>
III. Motivational and Social Determinants of Questionable Beliefs
<P>
A. Seeing What we want to see: motivational determinants of belief.
<P>
We tend to believe what we want to believe. Arguments about capital
punishment and the selective use of data to support a given position.
Who wins in a given political debate. How we think of ourselves.
Of course, this capacity is constrained to some extent by reality.
<P>
B. Believing What we are told: the biasing effects of secondhand
information.
<P>
Sharpening and leveling in story telling: in relaying an event,
we pick out what we think is interesting or relavent, and such
choices are made on the basis of our biases. When relaying a message
or event, it rarely comes verbatim.
<P>
C. The Imagined agreement of others: exaggerated impression of
social support.
<P>
If we can find two people who agree with us, or sometimes even
one, well then &quot;everyone agrees with me.&quot; or &quot;everyone
thinks this.&quot;
<P>
The Excessive Impact of Confirmatory Information
<P>
 Many of the beliefs we hold are about the relationships between
two variables.
<P>
 1. belief that dreams come true: relationship between dream content
and real life.
<P>
 2. Belief that increased military spending by the US was partly
responsible for the changes in the USSR and Eastern Europe: relationship
between US defense expenditures and Soviet internal and external
policy.
<P>
Most of these relationships, and the evidence necessary to assess
their validity can be represented in the 2x2 table familiar to
most social scientists.  Consider the common belief that infertal
couples who adopt a child are subsequently more likely to conceive
than those who do not.  The evidence relevant to this belief can
be represented in the layout:

<CENTER><img src="twobytwo.gif" alt="twobytwo" align=middle></CENTER>
<P>
 In this layout, &quot;a&quot; represent the number of couples
who adopt and then conceive.  &quot;b&quot; represents the number
who adopt and do not conceive, etc.  To adequately assess whether
adoption leads to conception, it's necessary to compare the probability
of conception after adoping a/(a+b), with the probability of conception
after not adopting, c/(c+d).  There is now a large literature
on how well people evaluate this kind of information in assessing
the presence or strenth of such relationships.
<P>
 According to this research, although people sometimes perform
such &quot;covariation&quot; tasks with considerable accuracy,
there are as many or more occasions in which they perform poorly.
 A major culpret in people's poor performance seems to be an over-reliance
on instances that confirm the existence of a relationship -- cells
&quot;a&quot; and &quot;d&quot;.  In fact, many judgements seem
to be influenced almost exclusively by the information contained
in cell &quot;a&quot;.  In the example of the adoptive couples,
people are most influenced by the number (and salience -- conspicuousness)
of couples who adopt and subsequently conceive.  In so doing,
people implicitly confuse necessary and sufficient evidence: They
seem to be reasooning that if there are a fair number of such
positive cases, then the phenomenon must exist, or the relationship
must be valid.
<P>
 In one of the most direct demonstrations of this phenomenon,
two groups of people were asked different versions of the same
question.  One group was asked to assess whether practicing the
day before a tennis match is related to winning the match, and
a second group was asked to assess whether practicing the day
before the match is related to losing.  The participants were
asked to indicate what informatioon, from cells a, b, c, and d
above, they thoought was necessary to adequately assess whether
such a relationship existed.  The results were quite revealing:
Those testing whether practice leads to winning emphasized the
number of times playerss practiced and won; those testing whether
practicing leads to losing emphasized the number of times players
practiced and lost.
<P>
 The most likely reason for the excessive influce of confirmatory
information is that it is easier to deal with cognitively.
<P>
II. The Tendency to Seek Confirmatory Information
<P>
People exhibit the tendency to focus on positive or confirming
instances when they gather, rather than simply evaluate, information
relavant to a given belief or hypothesis
<P>
When trying to assess whether a belief is valid, people tend to
seek out information that would potentially confirm the belief,
over information that might disconfirm it.  In other words, people
ask questions or seek information for which the equivalent of
a &quot;yes&quot; response would lend credence to their hypothesis.
<P>
Each of the cards -- A, B, 2, 3 has a letter on one side and a
number on the other.  By turning over the cards, determine whether
&quot;all cards with a vowel on one side have an even number on
the other.&quot;
<P>
The common response is to turn over the &quot;A&quot; and &quot;2&quot;
cards, presumably because of their potential to provide evidence
consistent with the hypothesis.
<P>
However, turning over the 2 card could ONLY confirm the hypothesis
since a vowel on the other side would confirm it and a consonent
would be irrelavent.  The &quot;3&quot; card was rarely turned
over, though it is potentially as informative as any other and
because of its potential to invalidate the hypothesis in one quick
step.  A vowel on the other side guarntees that not all cards
with vowels on one side have an even number on the other.
<P>
 This experiment is particularly informative because it makes
it abundantly clear that the tendency too seek out information
consistent with a hypothesis does not necessarily stem from any
desire for the hypothesis to be true.
<P>
 The intuition that positive instances are somehow more informative
can be seen in an experiment done by a guy named Holt.  Elementary
school students who had 20 questions to identify an unknown number
between 1 and 10,000 cheer when the teacher tells them &quot;yes,
it is between 5000 and 10000&quot; but groan when he says &quot;no,
it is not between 5000 and 10000&quot; even though the latter
response is jut as informative as the former.
<P>
 The difficulty no doubt derives from the additional cognative
step that must be taken.  If it is NOT between 5000 and 10000
then it IS between 1 and 5000.
  <script src="/Master/QHSTPageEnd.js"></script>
</BODY>

</HTML>
